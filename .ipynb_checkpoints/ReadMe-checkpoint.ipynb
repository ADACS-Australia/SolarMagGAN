{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architectures\n",
    "---\n",
    "\n",
    "Let Ck denote a Convolution-BatchNorm-ReLU layer with k filters. CDk denotes a a Convolution-BatchNormDropout-ReLU layer with a dropout rate of 50%. All convolutions are 4× 4 spatial filters applied with stride 2. Convolutions in the encoder, and in the discriminator, downsample by a factor of 2, whereas in the decoder they upsample by a factor of 2.\n",
    "\n",
    "### Generator architectures\n",
    "The encoder-decoder architecture consists of:\n",
    "encoder:\n",
    "C64-C128-C256-C512-C512-C512-C512-C512\n",
    "decoder:\n",
    "CD512-CD512-CD512-C512-C256-C128-C64\n",
    "\n",
    "After the last layer in the decoder, a convolution is applied to map to the number of output channels (3 in general, except in colorization, where it is 2), followed by a Tanh function. As an exception to the above notation, BatchNorm\n",
    "is not applied to the first C64 layer in the encoder.\n",
    "All ReLUs in the encoder are leaky, with slope 0.2, while ReLUs in the decoder are not leaky.\n",
    "\n",
    "The U-Net architecture is identical except with skip connections between each layer i in the encoder and layer n−i in the decoder, where n is the total number of layers. The skip connections concatenate activations from layer i to\n",
    "layer n − i. This changes the number of channels in the decoder:\n",
    "U-Net decoder:\n",
    "CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "\n",
    "### Discriminator architectures\n",
    "The 70 × 70 discriminator architecture is:\n",
    "C64-C128-C256-C512\n",
    "After the last layer, a convolution is applied to map to a 1\n",
    "dimensional output, followed by a Sigmoid function. As an exception to the above notation, BatchNorm is not applied to the first C64 layer. All ReLUs are leaky, with slope 0.2. All other discriminators follow the same basic architecture, with depth varied to modify the receptive field size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training details\n",
    "---\n",
    "All networks were trained from scratch. Weights were initialized from a Gaussian distribution with mean 0 and standard deviation 0.02.\n",
    "Batch iteration : 200000\n",
    "Batch size : 1\n",
    "Optimizer : Adam optimizer\n",
    "Learning rate : 2e-4\n",
    "beta_1 : 0.5\n",
    "beta_2 : 0.999\n",
    "epsilon : 1e-07\n",
    "decay : 0.0\n",
    "amsgrad : False\n",
    "lambda : 100\n",
    "BatchNormalization\n",
    "momentum : 0.9\n",
    "epsilon : 1.01e-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
