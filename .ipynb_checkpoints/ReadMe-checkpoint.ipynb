{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architectures\n",
    "\n",
    "### Generator architectures\n",
    "\n",
    "The generator is consist of the encoder-decoder architecture:\n",
    "\n",
    "encoder:\n",
    "\n",
    "1. Conv2D(filers = 64, strides = 2), LeakyReLu(slope = 0.2)\n",
    "2. Conv2D(filers = 128, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "3. Conv2D(filers = 256, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "4. Conv2D(filers = 512, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "5. Conv2D(filers = 512, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "6. Conv2D(filers = 512, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "7. Conv2D(filers = 512, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "8. Conv2D(filers = 512, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "9. Conv2D(filers = 512, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "10. Conv2D(filers = 512, strides = 2), ReLu\n",
    "\n",
    "decoder:\n",
    "\n",
    "1. Conv2DTranspose(filter = 512, strides = 2), BatchNorm, Dropout(rate = 0.5), ReLU\n",
    "2. Conv2DTranspose(filter = 512, strides = 2), BatchNorm, Dropout(rate = 0.5), ReLU\n",
    "3. Conv2DTranspose(filter = 512, strides = 2), BatchNorm, Dropout(rate = 0.5), ReLU\n",
    "4. Conv2DTranspose(filter = 512, strides = 2), BatchNorm, ReLU\n",
    "5. Conv2DTranspose(filter = 512, strides = 2), BatchNorm, ReLU\n",
    "6. Conv2DTranspose(filter = 512, strides = 2), BatchNorm, ReLU\n",
    "7. Conv2DTranspose(filter = 256, strides = 2), BatchNorm, ReLU\n",
    "8. Conv2DTranspose(filter = 128, strides = 2), BatchNorm, ReLU\n",
    "9. Conv2DTranspose(filter = 64, strides = 2), BatchNorm, ReLU\n",
    "10. Conv2DTranspose(filter = 1, strides = 2), Tanh\n",
    "\n",
    "Also, the generator has skip-connections between layers of the encoder and layers of the decoder like the U-Net architecture. \n",
    "\n",
    "skip-connection:\n",
    "\n",
    "* encoder 1st layer - decoder 10th layer\n",
    "* encoder 2nd layer - decoder 9th layer\n",
    "* encoder 3rd layer - decoder 8th layer\n",
    "* encoder 4th layer - decoder 7th layer\n",
    "* encoder 5th layer - decoder 6th layer\n",
    "* encoder 6th layer - decoder 5th layer\n",
    "* encoder 7th layer - decoder 4th layer\n",
    "* encoder 8th layer - decoder 3rd layer\n",
    "* encoder 9th layer - decoder 2nd layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator architectures\n",
    "\n",
    "The discriminator architecture is described in the following notation:\n",
    "* Conv2D(filers = 64, strides = 2), LeakyReLu(slope = 0.2)\n",
    "* Conv2D(filers = 128, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "* Conv2D(filers = 256, strides = 2), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "* Conv2D(filers = 512, strides = 1), BatchNorm, LeakyReLu(slope = 0.2)\n",
    "* Conv2D(filers = 1, strides = 1), Sigmoid\n",
    "\n",
    "The receptive field size used in our discriminator is 126 x 126."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter\n",
    "\n",
    "#### Loss\n",
    "* Lamba : 100\n",
    "\n",
    "#### Batch\n",
    "\n",
    "* Batch iteration : 200000\n",
    "* Batch size : 1\n",
    "\n",
    "#### Optimizer \n",
    "* Optimizer : Adam solver\n",
    "* Learning rate : 0.0002\n",
    "* momentum beta 1 parameter : 0.5\n",
    "* momentum beta 2 parameter : 0.999"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
