{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f4f38704588>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from random import shuffle\n",
    "from imageio import imread\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, \\\n",
    "    BatchNormalization, Input, Dropout\n",
    "from keras.layers import Conv2DTranspose, Activation, Cropping2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import Adam\n",
    "import argparse\n",
    "\n",
    "\n",
    "# configure os environment\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "# configure keras\n",
    "K.set_image_data_format('channels_last')\n",
    "CH_AXIS = -1\n",
    "\n",
    "# configure tensorflow\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "NITERS = 10  # total number of iterations\n",
    "# number of iterations before display and model creation\n",
    "DISPLAY_ITERS = 1\n",
    "\n",
    "# the input data:\n",
    "# (originally AIA or Atmospheric Imaging Assembly)\n",
    "INPUT_DATA = \"AIA_1700\"\n",
    "# The data we want to reproduce:\n",
    "# (originally HMI or Helioseismic and Magnetic Imager)\n",
    "OUTPUT_DATA = 'HMI'\n",
    "\n",
    "ISIZE = 1024  # height of the image\n",
    "NC_IN = 1  # number of input channels (1 for greyscale, 3 for RGB)\n",
    "NC_OUT = 1  # number of output channels (1 for greyscale, 3 for RGB)\n",
    "BATCH_SIZE = 1  # number of images in each batch\n",
    "# max layers in the discriminator not including sigmoid activation:\n",
    "# 1 for 16, 2 for 34, 3 for 70, 4 for 142, and 5 for 286 (receptive field size)\n",
    "MAX_LAYERS = 3\n",
    "\n",
    "TRIAL_NAME = \"AIA_1700\"\n",
    "\n",
    "\n",
    "MODE = INPUT_DATA + '_to_' + OUTPUT_DATA  # folder name for saving the model\n",
    "\n",
    "IMAGE_PATH_INPUT = './DATA/TRAIN/'+INPUT_DATA+'/*.png'  # input file path\n",
    "IMAGE_PATH_OUTPUT = './DATA/TRAIN/'+OUTPUT_DATA+'/*.png'  # ouptut file path\n",
    "\n",
    "# make a folder for the trial if it doesn't already exist\n",
    "MODEL_PATH_MAIN = './MODELS/' + TRIAL_NAME + '/'\n",
    "# os.mkdir(MODEL_PATH_MAIN) if not os.path.exists(MODEL_PATH_MAIN) else None\n",
    "MODEL_PATH = MODEL_PATH_MAIN + MODE + '/'\n",
    "os.makedirs(MODEL_PATH) if not os.path.exists(MODEL_PATH) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates tensors with a normal distribution with (mean, standard deviation)\n",
    "# this is used as a matrix of weights\n",
    "CONV_INIT = RandomNormal(0, 0.02)\n",
    "GAMMA_INIT = RandomNormal(1., 0.02)\n",
    "\n",
    "\n",
    "# The loss function\n",
    "def LOSS_FN(OUTPUT, TARGET):\n",
    "    return -K.mean(K.log(OUTPUT+1e-12)*TARGET+K.log(1-OUTPUT+1e-12)*(1-TARGET))\n",
    "\n",
    "\n",
    "# create a convolutional layer with f filters, and arguments a and k\n",
    "def DN_CONV(f, *a, **k):\n",
    "    return Conv2D(f, kernel_initializer=CONV_INIT, *a, **k)\n",
    "\n",
    "\n",
    "# create a deconvolutional layer with f filters, and arguments a and k\n",
    "def UP_CONV(f, *a, **k):\n",
    "    return Conv2DTranspose(f, kernel_initializer=CONV_INIT, *a, **k)\n",
    "\n",
    "\n",
    "# applies normalisation such that max is 1, and minimum is 0\n",
    "def BATNORM():\n",
    "    return BatchNormalization(\n",
    "                              momentum=0.9,\n",
    "                              axis=CH_AXIS,\n",
    "                              epsilon=1.01e-5,\n",
    "                              gamma_initializer=GAMMA_INIT\n",
    "                              )\n",
    "\n",
    "\n",
    "# leaky ReLU (y = alpha*x for x < 0, y = x for x > 0)\n",
    "def LEAKY_RELU(alpha):\n",
    "    return LeakyReLU(alpha)\n",
    "\n",
    "\n",
    "#  the descriminator\n",
    "def BASIC_D(ISIZE, NC_IN, NC_OUT, MAX_LAYERS):\n",
    "    # combines the inputs from the generator and the desired input\n",
    "    INPUT_A, INPUT_B = Input(shape=(ISIZE, ISIZE, NC_IN)),\\\n",
    "        Input(shape=(ISIZE, ISIZE, NC_OUT))\n",
    "\n",
    "    INPUT = Concatenate(axis=CH_AXIS)([INPUT_A, INPUT_B])\n",
    "\n",
    "    if MAX_LAYERS == 0:\n",
    "        N_FEATURE = 1  # number of filters to use\n",
    "        # apply sigmoid activation\n",
    "        L = DN_CONV(N_FEATURE,\n",
    "                    kernel_size=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid'\n",
    "                    )(INPUT)\n",
    "\n",
    "    else:\n",
    "        N_FEATURE = 64  # number of filters to use\n",
    "        # apply convolution\n",
    "        L = DN_CONV(N_FEATURE,\n",
    "                    kernel_size=4,\n",
    "                    strides=2,\n",
    "                    padding=\"same\"\n",
    "                    )(INPUT)\n",
    "        # Apply leaky ReLU activation with a slope of 0.2\n",
    "        L = LEAKY_RELU(0.2)(L)\n",
    "\n",
    "        # Apply convolution MAX_LAYERS times\n",
    "        for i in range(1, MAX_LAYERS):\n",
    "            N_FEATURE *= 2  # double the number of filters\n",
    "            # Apply convolution\n",
    "            L = DN_CONV(N_FEATURE,\n",
    "                        kernel_size=4,\n",
    "                        strides=2,\n",
    "                        padding=\"same\"\n",
    "                        )(L)\n",
    "            # normalise\n",
    "            L = BATNORM()(L, training=1)\n",
    "            # Apply leaky ReLU activation with a slope of 0.2\n",
    "            L = LEAKY_RELU(0.2)(L)\n",
    "\n",
    "        N_FEATURE *= 2  # double the number of filters\n",
    "        L = ZeroPadding2D(1)(L)  # pads the model with 0s with a thickness of 1\n",
    "        # Apply convolution\n",
    "        L = DN_CONV(N_FEATURE, kernel_size=4, padding=\"valid\")(L)\n",
    "        # normalise\n",
    "        L = BATNORM()(L, training=1)\n",
    "        # Apply leaky ReLU activation with a slope of 0.2\n",
    "        L = LEAKY_RELU(0.2)(L)\n",
    "\n",
    "        N_FEATURE = 1\n",
    "        L = ZeroPadding2D(1)(L)  # pads the model with 0s with a thickness of 1\n",
    "        # Apply sigmoid activation\n",
    "        L = DN_CONV(N_FEATURE,\n",
    "                    kernel_size=4,\n",
    "                    padding=\"valid\",\n",
    "                    activation='sigmoid'\n",
    "                    )(L)\n",
    "\n",
    "    return Model(inputs=[INPUT_A, INPUT_B], outputs=L)\n",
    "\n",
    "\n",
    "# The generator (based on the U-Net architecture)\n",
    "def UNET_G(ISIZE, NC_IN, NC_OUT, FIXED_INPUT_SIZE=True):\n",
    "    MAX_N_FEATURE = 64 * 8  # max number of filters to use\n",
    "\n",
    "    def BLOCK(X, S, NF_IN, USE_BATNORM=True, NF_OUT=None, NF_NEXT=None):\n",
    "        # Encoder: (decreasing size)\n",
    "\n",
    "        assert S >= 2 and S % 2 == 0\n",
    "        if NF_NEXT is None:  # number of filters in the next layer?\n",
    "            # set number of filters to twice the number of filters in the\n",
    "            # input, if it isn't more than the max number of filters\n",
    "            NF_NEXT = min(NF_IN*2, MAX_N_FEATURE)\n",
    "        if NF_OUT is None:\n",
    "            NF_OUT = NF_IN\n",
    "        # Apply convolution\n",
    "        X = DN_CONV(NF_NEXT,\n",
    "                    kernel_size=4,\n",
    "                    strides=2,\n",
    "                    # don't use a bias if batch normalisation will be done\n",
    "                    # later, or if s > 2\n",
    "                    use_bias=(not (USE_BATNORM and S > 2)),\n",
    "                    padding=\"same\"\n",
    "                    )(X)\n",
    "        if S > 2:\n",
    "            # apply batch normalisation\n",
    "            if USE_BATNORM:\n",
    "                X = BATNORM()(X, training=1)\n",
    "            # apply leaky ReLU with a slope of 0,2\n",
    "            X2 = LEAKY_RELU(0.2)(X)\n",
    "            # continue recursion until size = 2, halving size each time\n",
    "            X2 = BLOCK(X2, S//2, NF_NEXT)\n",
    "            # combine X and X2\n",
    "            # this gives the \"skip connections\" between the encoder layers\n",
    "            # and decoder layers.\n",
    "            X = Concatenate(axis=CH_AXIS)([X, X2])\n",
    "\n",
    "        # Decoder: (Increasing size)\n",
    "        # This happens only when the recursive encoder has reached its maximum\n",
    "        # depth (size = 2)\n",
    "        # Note the minimum layer size is actually s = 4, as encoding stops when\n",
    "        # s = 2\n",
    "\n",
    "        # Apply ReLU activation\n",
    "        X = Activation(\"relu\")(X)\n",
    "\n",
    "        # Apply deconvolution\n",
    "        X = UP_CONV(NF_OUT,\n",
    "                    kernel_size=4,\n",
    "                    strides=2,\n",
    "                    use_bias=not USE_BATNORM\n",
    "                    )(X)\n",
    "        X = Cropping2D(1)(X)\n",
    "        # Batch normalisation\n",
    "        if USE_BATNORM:\n",
    "            X = BATNORM()(X, training=1)\n",
    "        # apply dropout\n",
    "        # Randomly drops units which helps prevent overfitting\n",
    "        if S <= 8:\n",
    "            X = Dropout(0.5)(X, training=1)\n",
    "        return X\n",
    "\n",
    "    S = ISIZE if FIXED_INPUT_SIZE else None  # size\n",
    "    X = INPUT = Input(shape=(S, S, NC_IN))  # The input\n",
    "    # Apply the U-Net convolution, deconvolution (see above function)\n",
    "    X = BLOCK(X, ISIZE, NC_IN, False, NF_OUT=NC_OUT, NF_NEXT=64)\n",
    "    # Apply tanh activation\n",
    "    X = Activation('tanh')(X)\n",
    "\n",
    "    return Model(inputs=INPUT, outputs=[X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cam/anaconda3/envs/winter_project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The discriminator model\n",
    "NET_D = BASIC_D(ISIZE, NC_IN, NC_OUT, MAX_LAYERS)\n",
    "# The generator model\n",
    "NET_G = UNET_G(ISIZE, NC_IN, NC_OUT)\n",
    "\n",
    "# tensor placeholders?\n",
    "REAL_A = NET_G.input  # generator input (AIA)\n",
    "FAKE_B = NET_G.output  # generator output (fake HMI)\n",
    "REAL_B = NET_D.inputs[1]  # descriminator input (real HMI)\n",
    "\n",
    "# output of the discriminator for AIA and real HMI\n",
    "OUTPUT_D_REAL = NET_D([REAL_A, REAL_B])\n",
    "# output of the discriminator for AIA and fake HMI\n",
    "OUTPUT_D_FAKE = NET_D([REAL_A, FAKE_B])\n",
    "\n",
    "# set initial values for the loss\n",
    "# ones_like creates a tensor of the same shape full of ones\n",
    "# zeros_like creates a tensor of the same shape full of zeros\n",
    "# as the discriminator gives the probability that the input is a real HMI\n",
    "# picture, we want it to out put 1 when the input is real and 0 when the\n",
    "# input is fake.\n",
    "LOSS_D_REAL = LOSS_FN(OUTPUT_D_REAL, K.ones_like(OUTPUT_D_REAL))\n",
    "LOSS_D_FAKE = LOSS_FN(OUTPUT_D_FAKE, K.zeros_like(OUTPUT_D_FAKE))\n",
    "# while the generator, we want the discriminator to guess that the\n",
    "# generator output is the real HMI, which corresponds to the discriminator\n",
    "# outputting 1:\n",
    "LOSS_G_FAKE = LOSS_FN(OUTPUT_D_FAKE, K.ones_like(OUTPUT_D_FAKE))\n",
    "\n",
    "# total average difference between the real and generated HMIs\n",
    "LOSS_L = K.mean(K.abs(FAKE_B-REAL_B))\n",
    "\n",
    "# Total loss of the discriminator\n",
    "LOSS_D = LOSS_D_REAL + LOSS_D_FAKE\n",
    "# gives the updates for the discriminator training\n",
    "TRAINING_UPDATES_D = Adam(lr=2e-4, beta_1=0.5\n",
    "                          ).get_updates(NET_D.trainable_weights, [], LOSS_D)\n",
    "# creates a function that trains the discriminator\n",
    "NET_D_TRAIN = K.function([REAL_A, REAL_B], [LOSS_D/2.0], TRAINING_UPDATES_D)\n",
    "\n",
    "# The total loss of G, which includes the difference between the real and\n",
    "# generated HMIs, as well as the loss because of the descriminator\n",
    "LOSS_G = LOSS_G_FAKE + 100 * LOSS_L\n",
    "\n",
    "# operation to update the gradient of the generator using the adam optimizer\n",
    "TRAINING_UPDATES_G = Adam(\n",
    "                          lr=2e-4,\n",
    "                          beta_1=0.5\n",
    "                          ).get_updates(NET_G.trainable_weights, [], LOSS_G)\n",
    "# function to train the generator\n",
    "NET_G_TRAIN = K.function([REAL_A, REAL_B],\n",
    "                         [LOSS_G_FAKE, LOSS_L],\n",
    "                         TRAINING_UPDATES_G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# returns list of files that match FILE_PATTERN\n",
    "def LOAD_DATA(FILE_PATTERN):\n",
    "    return glob.glob(FILE_PATTERN)\n",
    "\n",
    "\n",
    "def GET_DATE(file):\n",
    "    filename = file.split(\"/\")[-1]  # filename is at end of file path\n",
    "    date_str = filename.split(\".\")[2]  # date string is after second \".\"\n",
    "    date_str = date_str.replace(\"_\", \"\")  # remove underscores\n",
    "    date_str = date_str.replace(\"-\", \"\")  # remove hyphens\n",
    "    date_str = date_str.replace(\"TAI\", \"z\")  # TAI and Z are both UTC\n",
    "    date = pd.Timestamp(date_str)\n",
    "    return date\n",
    "\n",
    "\n",
    "def GET_TIMESTAMP(file):\n",
    "    date = GET_DATE(file)\n",
    "    return date.timestamp()\n",
    "\n",
    "\n",
    "# FN = filenames, NC_IN = #channels in input, NC_OUT = #channels in output\n",
    "# This function essentially reads the image, and shifts it slightly by up\n",
    "# to 15 pixels any direction before returning it. This is probably to\n",
    "# prevent overfitting\n",
    "def READ_IMAGE(FN, NC_IN, NC_OUT):\n",
    "    IMG_A = imread(FN[0])\n",
    "    IMG_B = imread(FN[1])\n",
    "    X, Y = np.random.randint(31), np.random.randint(31)\n",
    "    if NC_IN != 1:\n",
    "        IMG_A = np.pad(IMG_A, ((15, 15), (15, 15), (0, 0)), 'constant')\n",
    "        IMG_A = IMG_A[X:X + 1024, Y:Y + 1024, :] / 255.0 * 2 - 1\n",
    "    else:\n",
    "        IMG_A = np.pad(IMG_A, 15, 'constant')\n",
    "        IMG_A = IMG_A[X:X + 1024, Y:Y + 1024] / 255.0 * 2 - 1\n",
    "\n",
    "    if NC_OUT != 1:\n",
    "        IMG_B = np.pad(IMG_B, ((15, 15), (15, 15), (0, 0)), 'constant')\n",
    "        IMG_B = IMG_B[X:X + 1024, Y:Y + 1024, :] / 255.0 * 2 - 1\n",
    "    else:\n",
    "        IMG_B = np.pad(IMG_B, 15, 'constant')\n",
    "        IMG_B = IMG_B[X:X + 1024, Y:Y + 1024] / 255.0 * 2 - 1\n",
    "\n",
    "    return IMG_A, IMG_B\n",
    "\n",
    "\n",
    "# create mini batches for training (actually creates a generator\n",
    "# that generates each element of the batch)\n",
    "def MINI_BATCH(DATA_AB, BATCH_SIZE, NC_IN, NC_OUT):\n",
    "    LENGTH = len(DATA_AB)\n",
    "    EPOCH = i = 0\n",
    "    TMP_SIZE = None\n",
    "    while True:\n",
    "        SIZE = TMP_SIZE if TMP_SIZE else BATCH_SIZE\n",
    "        # if we reach the end of the data (which corresponds to an\n",
    "        # epoch), shuffle data and begin again\n",
    "        if i + SIZE > LENGTH:\n",
    "            shuffle(DATA_AB)\n",
    "            i = 0\n",
    "            EPOCH += 1\n",
    "        DATA_A = []\n",
    "        DATA_B = []\n",
    "        # make batches of length: SIZE\n",
    "        for J in range(i, i + SIZE):\n",
    "            IMG_A, IMG_B = READ_IMAGE(DATA_AB[J], NC_IN, NC_OUT)\n",
    "            DATA_A.append(IMG_A)\n",
    "            DATA_B.append(IMG_B)\n",
    "        DATA_A = np.float32(DATA_A)\n",
    "        DATA_B = np.float32(DATA_B)\n",
    "        i += SIZE\n",
    "        TMP_SIZE = yield EPOCH, DATA_A, DATA_B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Output Pairs:\n",
      "[('./DATA/TRAIN/AIA_1700/aia.lev1_uv_24s.2011-01-01T000032Z.1700.image_lev1.png', './DATA/TRAIN/HMI/hmi.m_45s.20110101_000045_TAI.2.magnetogram.png')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input data\n",
    "LIST_INPUT = LOAD_DATA(IMAGE_PATH_INPUT)\n",
    "# output data\n",
    "LIST_OUTPUT = LOAD_DATA(IMAGE_PATH_OUTPUT)\n",
    "\n",
    "# sort lists based on timestamp\n",
    "LIST_OUTPUT = sorted(LIST_OUTPUT, key=GET_TIMESTAMP)\n",
    "LIST_INPUT = sorted(LIST_INPUT, key=GET_TIMESTAMP)\n",
    "\n",
    "\n",
    "i = 0  # index of LIST_INPUT\n",
    "j = 0  # index of LIST_OUTPUT\n",
    "\n",
    "# only keep images that are in both input and output\n",
    "while i < len(LIST_INPUT) and j < len(LIST_OUTPUT):\n",
    "    input = LIST_INPUT[i]\n",
    "    in_time = GET_DATE(input)\n",
    "    output = LIST_OUTPUT[j]\n",
    "    out_time = GET_DATE(output)\n",
    "    # if input is after output, delete output:\n",
    "    if in_time.date() > out_time.date():\n",
    "        del(LIST_OUTPUT[j])\n",
    "    # if input is before output, delete input:\n",
    "    elif in_time.date() < out_time.date():\n",
    "        del(LIST_INPUT[i])\n",
    "    # if input is after output, delete output:\n",
    "    elif in_time.hour > out_time.hour:\n",
    "        del(LIST_OUTPUT[j])\n",
    "    # if input is before output, delete input:\n",
    "    elif in_time.hour < out_time.hour:\n",
    "        del(LIST_INPUT[i])\n",
    "    # else, date and hours are the same, so we have a pair!\n",
    "    else:\n",
    "        # increment both lists\n",
    "        i += 1\n",
    "        j += 1\n",
    "\n",
    "# trim ends of lists so they are the same size\n",
    "length = min(i, j)\n",
    "LIST_INPUT = LIST_INPUT[:length]\n",
    "LIST_OUTPUT = LIST_OUTPUT[:length]\n",
    "\n",
    "assert len(LIST_INPUT) == len(LIST_OUTPUT)\n",
    "\n",
    "# zips the data such that each element is a (input, output) pair\n",
    "LIST_TOTAL = list(zip(sorted(LIST_INPUT), sorted(LIST_OUTPUT)))\n",
    "\n",
    "print(\"Input Output Pairs:\")\n",
    "print(LIST_TOTAL)\n",
    "# creates a generator to use for training\n",
    "TRAIN_BATCH = MINI_BATCH(LIST_TOTAL, BATCH_SIZE, NC_IN, NC_OUT)\n",
    "\n",
    "# initialise training variables\n",
    "T0 = T1 = time.time()\n",
    "GEN_ITERS = 0\n",
    "ERR_L = 0\n",
    "EPOCH = 0\n",
    "ERR_G = 0\n",
    "ERR_L_SUM = 0\n",
    "ERR_G_SUM = 0\n",
    "ERR_D_SUM = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0][1/10] LOSS_D: 0.860 LOSS_G: 2.039 LOSS_L: 0.382 T:70sec/1its, Total T: 70\n",
      "[1][2/10] LOSS_D: 1.996 LOSS_G: 0.938 LOSS_L: 0.309 T:25sec/1its, Total T: 100\n",
      "[2][3/10] LOSS_D: 0.772 LOSS_G: 1.332 LOSS_L: 0.268 T:26sec/1its, Total T: 127\n",
      "[3][4/10] LOSS_D: 1.225 LOSS_G: 0.876 LOSS_L: 0.236 T:28sec/1its, Total T: 157\n",
      "[4][5/10] LOSS_D: 0.837 LOSS_G: 0.937 LOSS_L: 0.207 T:26sec/1its, Total T: 185\n",
      "[5][6/10] LOSS_D: 0.861 LOSS_G: 0.824 LOSS_L: 0.182 T:27sec/1its, Total T: 213\n",
      "[6][7/10] LOSS_D: 0.705 LOSS_G: 0.805 LOSS_L: 0.163 T:25sec/1its, Total T: 240\n",
      "[7][8/10] LOSS_D: 0.660 LOSS_G: 0.811 LOSS_L: 0.150 T:26sec/1its, Total T: 268\n",
      "[8][9/10] LOSS_D: 0.639 LOSS_G: 0.849 LOSS_L: 0.136 T:28sec/1its, Total T: 297\n",
      "[9][10/10] LOSS_D: 0.620 LOSS_G: 0.878 LOSS_L: 0.121 T:24sec/1its, Total T: 327\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# training:\n",
    "while GEN_ITERS <= NITERS:\n",
    "    EPOCH, TRAIN_A, TRAIN_B = next(TRAIN_BATCH)\n",
    "    # input data set\n",
    "    TRAIN_A = TRAIN_A.reshape((BATCH_SIZE, ISIZE, ISIZE, NC_IN))\n",
    "    # output data set\n",
    "    TRAIN_B = TRAIN_B.reshape((BATCH_SIZE, ISIZE, ISIZE, NC_OUT))\n",
    "\n",
    "    # descriminator training and error\n",
    "    ERR_D,  = NET_D_TRAIN([TRAIN_A, TRAIN_B])\n",
    "    ERR_D_SUM += ERR_D\n",
    "\n",
    "    # generator training and error\n",
    "    ERR_G, ERR_L = NET_G_TRAIN([TRAIN_A, TRAIN_B])\n",
    "    ERR_G_SUM += ERR_G\n",
    "    ERR_L_SUM += ERR_L\n",
    "\n",
    "    GEN_ITERS += 1\n",
    "\n",
    "    # print training summary and save model\n",
    "    if GEN_ITERS % DISPLAY_ITERS == 0:\n",
    "        print('[%d][%d/%d] LOSS_D: %5.3f LOSS_G: %5.3f LOSS_L: %5.3f T:'\n",
    "              '%dsec/%dits, Total T: %d'\n",
    "              % (\n",
    "                 EPOCH, GEN_ITERS, NITERS, ERR_D_SUM/DISPLAY_ITERS,\n",
    "                 ERR_G_SUM/DISPLAY_ITERS, ERR_L_SUM/DISPLAY_ITERS,\n",
    "                 time.time()-T1, DISPLAY_ITERS, time.time()-T0\n",
    "                 )\n",
    "              )\n",
    "\n",
    "        ERR_L_SUM = 0\n",
    "        ERR_G_SUM = 0\n",
    "        ERR_D_SUM = 0\n",
    "        DST_MODEL = MODEL_PATH+MODE+'_ITER'+'%07d' % GEN_ITERS+'.h5'\n",
    "        NET_G.save(DST_MODEL)\n",
    "        T1 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
